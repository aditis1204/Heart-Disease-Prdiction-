{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Random_Forest.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4RmVW5uD0F9",
        "colab_type": "code",
        "outputId": "e9c46078-ffd4-436a-8eaa-263c6f43072b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import matplotlib\n",
        "import keras\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas.plotting import scatter_matrix"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrQTWLnBD9lq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the heart disease dataset\n",
        "url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n",
        "\n",
        "# the names will be the names of each column in our pandas DataFrame\n",
        "names = ['age',\n",
        "        'sex',\n",
        "        'cp',\n",
        "        'trestbps',\n",
        "        'chol',\n",
        "        'fbs',\n",
        "        'restecg',\n",
        "        'thalach',\n",
        "        'exang',\n",
        "        'oldpeak',\n",
        "        'slope',\n",
        "        'ca',\n",
        "        'thal',\n",
        "        'class']\n",
        "\n",
        "# read the csv\n",
        "cleveland = pd.read_csv(url, names=names)\n",
        "data=cleveland"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFnyWmPgEDrq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data[~data.isin(['?'])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei6nIVR-EHwQ",
        "colab_type": "code",
        "outputId": "3c4cc0e9-9dbd-474c-b895-210221d93b7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "data = data.dropna(axis=0)\n",
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(297, 14)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iz-oiQmpLGoc",
        "colab_type": "code",
        "outputId": "587b49d8-c2ce-4ba2-8192-b7f0701c062b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "data = data.apply(pd.to_numeric)\n",
        "data.dtypes\n",
        "print (data.shape)\n",
        "print (data.dtypes)\n",
        "print(data)\n",
        "colnames_numeric = data.columns[0:14]\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "data[colnames_numeric] = scaler.fit_transform(data[colnames_numeric])\n",
        "X = np.array(data)\n",
        "y = np.array(data['class'])\n",
        "\n",
        "print(X)\n",
        "y\n",
        "y[y>0]=1\n",
        "\n",
        "data['class']=y\n",
        "\n",
        "df = data.values.tolist()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(297, 14)\n",
            "age         float64\n",
            "sex         float64\n",
            "cp          float64\n",
            "trestbps    float64\n",
            "chol        float64\n",
            "fbs         float64\n",
            "restecg     float64\n",
            "thalach     float64\n",
            "exang       float64\n",
            "oldpeak     float64\n",
            "slope       float64\n",
            "ca          float64\n",
            "thal        float64\n",
            "class         int64\n",
            "dtype: object\n",
            "      age  sex   cp  trestbps   chol  ...  oldpeak  slope   ca  thal  class\n",
            "0    63.0  1.0  1.0     145.0  233.0  ...      2.3    3.0  0.0   6.0      0\n",
            "1    67.0  1.0  4.0     160.0  286.0  ...      1.5    2.0  3.0   3.0      2\n",
            "2    67.0  1.0  4.0     120.0  229.0  ...      2.6    2.0  2.0   7.0      1\n",
            "3    37.0  1.0  3.0     130.0  250.0  ...      3.5    3.0  0.0   3.0      0\n",
            "4    41.0  0.0  2.0     130.0  204.0  ...      1.4    1.0  0.0   3.0      0\n",
            "..    ...  ...  ...       ...    ...  ...      ...    ...  ...   ...    ...\n",
            "297  57.0  0.0  4.0     140.0  241.0  ...      0.2    2.0  0.0   7.0      1\n",
            "298  45.0  1.0  1.0     110.0  264.0  ...      1.2    2.0  0.0   7.0      1\n",
            "299  68.0  1.0  4.0     144.0  193.0  ...      3.4    2.0  2.0   7.0      2\n",
            "300  57.0  1.0  4.0     130.0  131.0  ...      1.2    2.0  1.0   7.0      3\n",
            "301  57.0  0.0  2.0     130.0  236.0  ...      0.0    2.0  1.0   3.0      1\n",
            "\n",
            "[297 rows x 14 columns]\n",
            "[[0.70833333 1.         0.         ... 0.         0.75       0.        ]\n",
            " [0.79166667 1.         1.         ... 1.         0.         0.5       ]\n",
            " [0.79166667 1.         1.         ... 0.66666667 1.         0.25      ]\n",
            " ...\n",
            " [0.8125     1.         1.         ... 0.66666667 1.         0.5       ]\n",
            " [0.58333333 1.         1.         ... 0.33333333 1.         0.75      ]\n",
            " [0.58333333 0.         0.33333333 ... 0.33333333 0.         0.25      ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aI98lli8GfKv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=data.rename(columns={0: 'age', 1:'sex', 2:'cp', 3:'trestbps',4: 'chol',5: 'fbs',6: 'restecg',7: 'thalach',8: 'exang',9: 'oldpeak',10: 'slope',11: 'ca',12: 'thal',13:'target'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDU1zLzgF6yx",
        "colab_type": "code",
        "outputId": "d1ec6c9b-36ed-4449-e532-9cebf71c35b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.708333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.481132</td>\n",
              "      <td>0.244292</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.603053</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.370968</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.791667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.622642</td>\n",
              "      <td>0.365297</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.282443</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.241935</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.791667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.245283</td>\n",
              "      <td>0.235160</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.442748</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.419355</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.166667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.339623</td>\n",
              "      <td>0.283105</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.885496</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.564516</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.339623</td>\n",
              "      <td>0.178082</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.770992</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.225806</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.433962</td>\n",
              "      <td>0.262557</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.396947</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.032258</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.150943</td>\n",
              "      <td>0.315068</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.465649</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.193548</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>0.812500</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.471698</td>\n",
              "      <td>0.152968</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.534351</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.548387</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>0.583333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.339623</td>\n",
              "      <td>0.011416</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.335878</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.193548</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.339623</td>\n",
              "      <td>0.251142</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.786260</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>297 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          age  sex        cp  trestbps  ...  slope        ca  thal  class\n",
              "0    0.708333  1.0  0.000000  0.481132  ...    1.0  0.000000  0.75    0.0\n",
              "1    0.791667  1.0  1.000000  0.622642  ...    0.5  1.000000  0.00    1.0\n",
              "2    0.791667  1.0  1.000000  0.245283  ...    0.5  0.666667  1.00    1.0\n",
              "3    0.166667  1.0  0.666667  0.339623  ...    1.0  0.000000  0.00    0.0\n",
              "4    0.250000  0.0  0.333333  0.339623  ...    0.0  0.000000  0.00    0.0\n",
              "..        ...  ...       ...       ...  ...    ...       ...   ...    ...\n",
              "297  0.583333  0.0  1.000000  0.433962  ...    0.5  0.000000  1.00    1.0\n",
              "298  0.333333  1.0  0.000000  0.150943  ...    0.5  0.000000  1.00    1.0\n",
              "299  0.812500  1.0  1.000000  0.471698  ...    0.5  0.666667  1.00    1.0\n",
              "300  0.583333  1.0  1.000000  0.339623  ...    0.5  0.333333  1.00    1.0\n",
              "301  0.583333  0.0  0.333333  0.339623  ...    0.5  0.333333  0.00    1.0\n",
              "\n",
              "[297 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2AbVOSbGLWq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 2. Distinguish categorical and continuous features\n",
        "def determine_type_of_feature(df):\n",
        "    \n",
        "    feature_types = []\n",
        "    n_unique_values_treshold = 15\n",
        "    for feature in df.columns:\n",
        "        if feature != \"label\":\n",
        "            unique_values = df[feature].unique()\n",
        "            example_value = unique_values[0]\n",
        "\n",
        "            if (isinstance(example_value, str)) or (len(unique_values) <= n_unique_values_treshold):\n",
        "                feature_types.append(\"categorical\")\n",
        "            else:\n",
        "                feature_types.append(\"continuous\")\n",
        "    \n",
        "    return feature_types\n",
        "\n",
        "\n",
        "# 3. Accuracy\n",
        "def calculate_accuracy(predictions, labels):\n",
        "    predictions_correct = predictions == labels\n",
        "    accuracy = predictions_correct.mean()\n",
        "    \n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38mbT9slIaaR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def check_purity(data):\n",
        "    \n",
        "    label_column = data[:, -1]\n",
        "    unique_classes = np.unique(label_column)\n",
        "\n",
        "    if len(unique_classes) == 1:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "    \n",
        "\n",
        "def classify_data(data):\n",
        "    \n",
        "    label_column = data[:, -1]\n",
        "    unique_classes, counts_unique_classes = np.unique(label_column, return_counts=True)\n",
        "\n",
        "    index = counts_unique_classes.argmax()\n",
        "    classification = unique_classes[index]\n",
        "    \n",
        "    return classification\n",
        "\n",
        "\n",
        "\n",
        "def get_potential_splits(data, random_subspace):\n",
        "    \n",
        "    potential_splits = {}\n",
        "    _, n_columns = data.shape\n",
        "    column_indices = list(range(n_columns - 1))    # excluding the last column which is the label\n",
        "    \n",
        "    if random_subspace and random_subspace <= len(column_indices):\n",
        "        column_indices = random.sample(population=column_indices, k=random_subspace)\n",
        "    \n",
        "    for column_index in column_indices:          \n",
        "        values = data[:, column_index]\n",
        "        unique_values = np.unique(values)\n",
        "        \n",
        "        potential_splits[column_index] = unique_values\n",
        "    \n",
        "    return potential_splits\n",
        "\n",
        "\n",
        "\n",
        "def calculate_entropy(data):\n",
        "    \n",
        "    label_column = data[:, -1]\n",
        "    _, counts = np.unique(label_column, return_counts=True)\n",
        "\n",
        "    probabilities = counts / counts.sum()\n",
        "    entropy = sum(probabilities * -np.log2(probabilities))\n",
        "     \n",
        "    return entropy\n",
        "\n",
        "\n",
        "def calculate_overall_entropy(data_below, data_above):\n",
        "    \n",
        "    n = len(data_below) + len(data_above)\n",
        "    p_data_below = len(data_below) / n\n",
        "    p_data_above = len(data_above) / n\n",
        "\n",
        "    overall_entropy =  (p_data_below * calculate_entropy(data_below) \n",
        "                      + p_data_above * calculate_entropy(data_above))\n",
        "    \n",
        "    return overall_entropy\n",
        "\n",
        "\n",
        "def determine_best_split(data, potential_splits):\n",
        "    \n",
        "    overall_entropy = 9999\n",
        "    for column_index in potential_splits:\n",
        "        for value in potential_splits[column_index]:\n",
        "            data_below, data_above = split_data(data, split_column=column_index, split_value=value)\n",
        "            current_overall_entropy = calculate_overall_entropy(data_below, data_above)\n",
        "            \n",
        "            if current_overall_entropy <= overall_entropy:\n",
        "                overall_entropy = current_overall_entropy\n",
        "                best_split_column = column_index\n",
        "                best_split_value = value\n",
        "    \n",
        "    return best_split_column, best_split_value\n",
        "\n",
        "\n",
        "# 1.5 Split data\n",
        "def split_data(data, split_column, split_value):\n",
        "    \n",
        "    split_column_values = data[:, split_column]\n",
        "\n",
        "    type_of_feature = FEATURE_TYPES[split_column]\n",
        "    if type_of_feature == \"continuous\":\n",
        "        data_below = data[split_column_values <= split_value]\n",
        "        data_above = data[split_column_values >  split_value]\n",
        "    \n",
        "    # feature is categorical   \n",
        "    else:\n",
        "        data_below = data[split_column_values == split_value]\n",
        "        data_above = data[split_column_values != split_value]\n",
        "    \n",
        "    return data_below, data_above\n",
        "\n",
        "\n",
        "\n",
        "def decision_tree_algorithm(df, counter=0, min_samples=2, max_depth=5, random_subspace=None):\n",
        "    \n",
        "    # data preparations\n",
        "    if counter == 0:\n",
        "        global COLUMN_HEADERS, FEATURE_TYPES\n",
        "        COLUMN_HEADERS = df.columns\n",
        "        FEATURE_TYPES = determine_type_of_feature(df)\n",
        "        data = df.values\n",
        "    else:\n",
        "        data = df           \n",
        "    \n",
        "    \n",
        "    # base cases\n",
        "    if (check_purity(data)) or (len(data) < min_samples) or (counter == max_depth):\n",
        "        classification = classify_data(data)\n",
        "        \n",
        "        return classification\n",
        "\n",
        "    \n",
        "    # recursive part\n",
        "    else:    \n",
        "        counter += 1\n",
        "\n",
        "        # helper functions \n",
        "        potential_splits = get_potential_splits(data, random_subspace)\n",
        "        split_column, split_value = determine_best_split(data, potential_splits)\n",
        "        data_below, data_above = split_data(data, split_column, split_value)\n",
        "        \n",
        "        # check for empty data\n",
        "        if len(data_below) == 0 or len(data_above) == 0:\n",
        "            classification = classify_data(data)\n",
        "            return classification\n",
        "        \n",
        "        # determine question\n",
        "        feature_name = COLUMN_HEADERS[split_column]\n",
        "        type_of_feature = FEATURE_TYPES[split_column]\n",
        "        if type_of_feature == \"continuous\":\n",
        "            question = \"{} <= {}\".format(feature_name, split_value)\n",
        "            \n",
        "        # feature is categorical\n",
        "        else:\n",
        "            question = \"{} = {}\".format(feature_name, split_value)\n",
        "        \n",
        "        # instantiate sub-tree\n",
        "        sub_tree = {question: []}\n",
        "        \n",
        "        # find answers (recursion)\n",
        "        yes_answer = decision_tree_algorithm(data_below, counter, min_samples, max_depth, random_subspace)\n",
        "        no_answer = decision_tree_algorithm(data_above, counter, min_samples, max_depth, random_subspace)\n",
        "        \n",
        "        # If the answers are the same, then there is no point in asking the qestion.\n",
        "        # This could happen when the data is classified even though it is not pure\n",
        "        # yet (min_samples or max_depth base case).\n",
        "        if yes_answer == no_answer:\n",
        "            sub_tree = yes_answer\n",
        "        else:\n",
        "            sub_tree[question].append(yes_answer)\n",
        "            sub_tree[question].append(no_answer)\n",
        "        \n",
        "        return sub_tree\n",
        "\n",
        "\n",
        "# 3. Make predictions\n",
        "# 3.1 One example\n",
        "def predict_example(example, tree):\n",
        "    question = list(tree.keys())[0]\n",
        "    feature_name, comparison_operator, value = question.split(\" \")\n",
        "\n",
        "    # ask question\n",
        "    if comparison_operator == \"<=\":\n",
        "        if example[feature_name] <= float(value):\n",
        "            answer = tree[question][0]\n",
        "        else:\n",
        "            answer = tree[question][1]\n",
        "    \n",
        "    # feature is categorical\n",
        "    else:\n",
        "        if str(example[feature_name]) == value:\n",
        "            answer = tree[question][0]\n",
        "        else:\n",
        "            answer = tree[question][1]\n",
        "\n",
        "    # base case\n",
        "    if not isinstance(answer, dict):\n",
        "        return answer\n",
        "    \n",
        "    # recursive part\n",
        "    else:\n",
        "        residual_tree = answer\n",
        "        return predict_example(example, residual_tree)\n",
        "\n",
        "    \n",
        "# 3.2 All examples of the test data\n",
        "def decision_tree_predictions(test_df, tree):\n",
        "    predictions = test_df.apply(predict_example, args=(tree,), axis=1)\n",
        "    return predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEO8sXgZJRCo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "train_df, test_df = train_test_split(data, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Puvx78uwJVt6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def bootstrapping(train_df, n_bootstrap):\n",
        "    bootstrap_indices = np.random.randint(low=0, high=len(train_df), size=n_bootstrap)\n",
        "    df_bootstrapped = train_df.iloc[bootstrap_indices]\n",
        "    \n",
        "    return df_bootstrapped\n",
        "\n",
        "def random_forest_algorithm(train_df, n_trees, n_bootstrap, n_features, dt_max_depth):\n",
        "    forest = []\n",
        "    for i in range(n_trees):\n",
        "        df_bootstrapped = bootstrapping(train_df, n_bootstrap)\n",
        "        tree = decision_tree_algorithm(df_bootstrapped, max_depth=dt_max_depth, random_subspace=n_features)\n",
        "        forest.append(tree)\n",
        "    \n",
        "    return forest\n",
        "\n",
        "def random_forest_predictions(test_df, forest):\n",
        "    df_predictions = {}\n",
        "    for i in range(len(forest)):\n",
        "        column_name = \"tree_{}\".format(i)\n",
        "        predictions = decision_tree_predictions(test_df, tree=forest[i])\n",
        "        df_predictions[column_name] = predictions\n",
        "\n",
        "    df_predictions = pd.DataFrame(df_predictions)\n",
        "    random_forest_predictions = df_predictions.mode(axis=1)[0]\n",
        "    \n",
        "    return random_forest_predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qr1tg8vZJX10",
        "colab_type": "code",
        "outputId": "d4c48d56-ac6c-4cd1-b289-0cec86cc6067",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "forest = random_forest_algorithm(train_df, n_trees=15, n_bootstrap=200, n_features=8, dt_max_depth=8)\n",
        "predictions = random_forest_predictions(test_df, forest)\n",
        "accuracy = calculate_accuracy(predictions, test_df['class'])\n",
        "\n",
        "#print(\"Accuracy = {}\".format(accuracy))\n",
        "print(\"Accuracy of Random forest=\", accuracy*100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Random forest= 81.66666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7rQEQBDJagN",
        "colab_type": "code",
        "outputId": "7344fbff-7011-4307-ed72-a5c368c076a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        }
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import make_scorer, confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "print(classification_report(test_df['class'], predictions))\n",
        "\n",
        "\n",
        "rf_cm = confusion_matrix(test_df['class'], predictions)\n",
        "\n",
        "ax = sns.heatmap(rf_cm,annot=True,cmap='coolwarm',fmt='.0f')\n",
        "ax.set_title('Random Forest Confusion Matrix')\n",
        "ax.set_ylabel('True Label')\n",
        "ax.set_xlabel('Predicted Label')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.83      0.85      0.84        34\n",
            "         1.0       0.80      0.77      0.78        26\n",
            "\n",
            "    accuracy                           0.82        60\n",
            "   macro avg       0.81      0.81      0.81        60\n",
            "weighted avg       0.82      0.82      0.82        60\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 15.0, 'Predicted Label')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}